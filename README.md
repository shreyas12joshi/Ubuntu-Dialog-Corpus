# Topic Models from Ubuntu Dialog Corpus

Detecting topics from multi-user chats (unstructured data) from Ubuntu Dialog Corpus.


## Pre-requisites

- Python 3 (Anaconda)
- NLTK
- scikit-learn
- Gensim
- NumPy

To run the code, please have the above installed and run the file (either .py as it is or the jupyter notebook cells sequentially.)

## Data Resource

- Ubuntu Dialog Corpus: http://dataset.cs.mcgill.ca/ubuntu-corpus-1.0/
- Raw dialogue files (two-way conversation, no pre-processing):Ubuntu dialogues (527M)
- Folder: 4

## Methodology

Data pre-processing: 

1) Removed " ' " from words, to make words like 'don't' and 'dont' as the same.
2) Lower-casing all the words.
3) RegexTokenizer.
4) Removing general stop words of english language, using stopwords from nltk.corpus.
5) Removing list of stop words specific to this data.
6) Using alphabetic strings.
7) WordNet Lemmatizer
7) For LDA: Filtered out words that occur less than 20 documents, or more than 50% of the documents.

ML models:

Since we do not know the topics and every document can fall under two or more topics, simpler models such as K-means clusterning are not useful here. Rather generative models such as Latent Dirichlet Allocation (LDA), where we have more control over data mean and variance are more helpful. We do not need to know number of topics and these allow the data to fall under more than one topics. Another such technique for approximate topic modeling is Non-negative Matrix Factorization (NMF).

Question 1: Finding the 10 most common topics:
- Used ngrams (unigrams/bigrams) to identify the common topics in the corpus. (Better data-processing techniques e.g. identifying better collocations will help in identifying more useful topics.)

- Results:
  - Unigrams: [(('ubuntu',), 120546), (('get',), 58644), (('install',), 58300), (('file',), 41868), (('window',), 32058),   (('linux',), 27608), (('using',), 26246), (('problem',), 25589), (('http',), 25558), (('sudo',), 24960)]

  - Bigrams: [(('apt', 'get'), 16059), (('ubuntu', 'com'), 9476), (('sudo', 'apt'), 7210), (('get', 'install'), 6862), (('http', 'www'), 5836), (('install', 'ubuntu'), 5214), (('live', 'cd'), 4596), (('command', 'line'), 3740), (('http', 'paste'), 3463), (('paste', 'ubuntu'), 3436)]

- Future step: identify these using word frequency in LDA.

Trained LDA for entire corpus (Folder 4 data). This part took most of the time since training LDA on the entire set is very time consuming.

Question 2: Topic Detector for any file:
- Used LDA
- Used NMF

Because of time constraints in training the entire corpus (with the computational power of my system), I could not compare the two models exhaustively. I have tested NMF on single file data as asked in question and generated topics. I trained LDA on a subset of entire data set. The topics generated by LDA are more consistent and made more sense.The results with NMF are not very impressive, since it is trained on just one file data. This needs a deeper investigation. 

Results:
- NMF: 
   - Topic 0: chan | english | havent | header | last | read | sorry | yes
   - Topic 1: italiano | qualche
   
- LDA:  
[([(0.28954569, 'server'),
   (0.28177148, 'desktop'),
   (0.23291631, 'ive'),
   (0.061962474, 'ubuntu'),
   (0.05725336, 'installed'),
   (0.050520916, 'way'),
   (0.0052354373, 'window'),
   (0.003671497, 'install'),
   (0.002895278, 'file'),
   (0.0023664536, 'get'),
   (0.001949152, 'see'),
   (0.0019079009, 'linux'),
   (0.0016758314, 'using'),
   (0.001599859, 'cd'),
   (0.001434224, 'sudo'),
   (0.001376336, 'command'),
   (0.00096506573, 'http'),
   (0.00095274666, 'com')]]

## Next steps

1. Using Wikipedia Dataset, to identify topic names.
2. More data pre-processing: removing user names from the chat conversations (implemented it for single file processing), finding better collocations etc.
3. Using Part-of-Speech tagging to identify some structure.
4. Using frequency distribution, finding most common topics using LDA.
5. Use entire corpus for more powerful analysis (using deep learning framework for faster computations).
6. Accuracy of LDA vs NMF on this corpus
